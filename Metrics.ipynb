{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ece0dc-e8e4-4fec-bcb3-29fd9230db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a37827d-dffb-4497-aa3c-0d84331c779a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>ImagePaths</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>images/3cca7146-1010_463.jpg</td>\n",
       "      <td>[4.2817576e-04 3.7263100e-05 1.7458877e-04 1.7...</td>\n",
       "      <td>[0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>images/f3fbe6f6-1129_73.jpg</td>\n",
       "      <td>[0.99998367 0.99999046 0.9998697  0.99998176]</td>\n",
       "      <td>[1 1 1 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>images/e5a1fc17-0828_136.jpg</td>\n",
       "      <td>[9.5956811e-06 7.4980258e-06 9.9998426e-01 2.3...</td>\n",
       "      <td>[0 0 1 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>images/6a310bf6-1001_209.jpg</td>\n",
       "      <td>[1.6568579e-04 6.3139241e-04 3.0443003e-05 9.9...</td>\n",
       "      <td>[0 0 0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>images/a8b62ddb-1010_843.jpg</td>\n",
       "      <td>[3.0744355e-05 5.4354418e-06 5.0321165e-07 2.4...</td>\n",
       "      <td>[0 0 0 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>9</td>\n",
       "      <td>images/a6d77a30-0828_753.jpg</td>\n",
       "      <td>[2.8116713e-04 9.9957854e-01 9.9933845e-01 9.9...</td>\n",
       "      <td>[0 1 1 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>9</td>\n",
       "      <td>images/50f4bcfb-1022_62.jpg</td>\n",
       "      <td>[0.9999949  0.99998116 0.9998857  0.9999963 ]</td>\n",
       "      <td>[1 1 1 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5502</th>\n",
       "      <td>9</td>\n",
       "      <td>images/3e7a2915-1010_738.jpg</td>\n",
       "      <td>[0.9713037  0.99998343 0.99992    0.00730028]</td>\n",
       "      <td>[1 1 1 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5503</th>\n",
       "      <td>9</td>\n",
       "      <td>images/16c773b0-1001_394.jpg</td>\n",
       "      <td>[0.01815899 0.0004658  0.00026154 0.00175294]</td>\n",
       "      <td>[1 0 0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>9</td>\n",
       "      <td>images/dcb6fae1-0828_841.jpg</td>\n",
       "      <td>[0.99996626 0.9999478  0.9999615  0.99997985]</td>\n",
       "      <td>[1 1 1 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5505 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold                    ImagePaths  \\\n",
       "0        0  images/3cca7146-1010_463.jpg   \n",
       "1        0   images/f3fbe6f6-1129_73.jpg   \n",
       "2        0  images/e5a1fc17-0828_136.jpg   \n",
       "3        0  images/6a310bf6-1001_209.jpg   \n",
       "4        0  images/a8b62ddb-1010_843.jpg   \n",
       "...    ...                           ...   \n",
       "5500     9  images/a6d77a30-0828_753.jpg   \n",
       "5501     9   images/50f4bcfb-1022_62.jpg   \n",
       "5502     9  images/3e7a2915-1010_738.jpg   \n",
       "5503     9  images/16c773b0-1001_394.jpg   \n",
       "5504     9  images/dcb6fae1-0828_841.jpg   \n",
       "\n",
       "                                            Predictions    Targets  \n",
       "0     [4.2817576e-04 3.7263100e-05 1.7458877e-04 1.7...  [0 0 0 0]  \n",
       "1         [0.99998367 0.99999046 0.9998697  0.99998176]  [1 1 1 1]  \n",
       "2     [9.5956811e-06 7.4980258e-06 9.9998426e-01 2.3...  [0 0 1 0]  \n",
       "3     [1.6568579e-04 6.3139241e-04 3.0443003e-05 9.9...  [0 0 0 1]  \n",
       "4     [3.0744355e-05 5.4354418e-06 5.0321165e-07 2.4...  [0 0 0 0]  \n",
       "...                                                 ...        ...  \n",
       "5500  [2.8116713e-04 9.9957854e-01 9.9933845e-01 9.9...  [0 1 1 1]  \n",
       "5501      [0.9999949  0.99998116 0.9998857  0.9999963 ]  [1 1 1 1]  \n",
       "5502      [0.9713037  0.99998343 0.99992    0.00730028]  [1 1 1 0]  \n",
       "5503      [0.01815899 0.0004658  0.00026154 0.00175294]  [1 0 0 1]  \n",
       "5504      [0.99996626 0.9999478  0.9999615  0.99997985]  [1 1 1 1]  \n",
       "\n",
       "[5505 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"Saved/preds_targets_probs_40e_10f.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d88a3b7e-49a4-490b-b0d3-1c79f9789a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse string arrays\n",
    "def parse_array(s):\n",
    "    return np.fromstring(s.strip(\"[]\"), sep=\" \")\n",
    "\n",
    "preds = results_df[\"Predictions\"].apply(parse_array).to_list()\n",
    "targets = results_df[\"Targets\"].apply(parse_array).to_list()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "preds = np.stack(preds)\n",
    "targets = np.stack(targets).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df001dee-cbe5-4c23-b490-2952944e26be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9275)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_acc = MultilabelExactMatch(num_labels = 4)\n",
    "subset_acc(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b1f973b-2b64-4284-9cc7-b5510a924847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance across all folds\n",
      "Total Samples: 5505\n",
      "\n",
      "TorchMetrics\n",
      "Macro Acc: 0.9781 | Micro Acc: 0.9781 | Weighted Acc: 0.9781\n",
      "Per Label Acc: [0.97947323 0.9782016  0.9782016  0.97656673]\n",
      "Subset Acc: 0.9275 | Marco-Ham: 0.0219 | Micro-Ham: 0.0219\n",
      "\n",
      "Macro AUROC:  0.9908         Macro AUPRC:  0.9873\n",
      "Micro AUROC:  0.9909         Micro AUPRC:  0.9877\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Right Upper     0.9794    0.9692    0.9743      2211\n",
      "  Left Upper     0.9775    0.9688    0.9732      2247\n",
      "  Left Lower     0.9744    0.9760    0.9752      2414\n",
      " Right Lower     0.9743    0.9714    0.9728      2378\n",
      "\n",
      "   micro avg     0.9763    0.9715    0.9739      9250\n",
      "   macro avg     0.9764    0.9714    0.9739      9250\n",
      "weighted avg     0.9763    0.9715    0.9739      9250\n",
      " samples avg     0.9782    0.9742    0.9629      9250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(preds, targets, target_names):\n",
    "\n",
    "    preds = torch.tensor(preds, dtype=torch.float32)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    tar_np = targets.detach().cpu().numpy()\n",
    "    pred_np = preds.detach().cpu().numpy()\n",
    "    preds_binary = (pred_np >= 0.5).astype(int) \n",
    "\n",
    "    subset_acc = MultilabelExactMatch(num_labels = 4)\n",
    "    macro_acc = MultilabelAccuracy(num_labels = 4, average = \"macro\")\n",
    "    micro_acc = MultilabelAccuracy(num_labels = 4, average = \"micro\")\n",
    "    weight_acc = MultilabelAccuracy(num_labels = 4, average = \"weighted\")\n",
    "    per_label_acc = MultilabelAccuracy(num_labels = 4, average = None)\n",
    "    \n",
    "    ham_macro = MultilabelHammingDistance(num_labels = 4 , average='macro')\n",
    "    ham_micro = MultilabelHammingDistance(num_labels = 4 , average='micro')\n",
    "    multilabel_auroc_ma = MultilabelAUROC(num_labels = 4, average = \"macro\", thresholds = None)    # multiclass AUROC\n",
    "    multilabel_auprc_ma = MultilabelAveragePrecision(num_labels = 4, average = \"macro\", thresholds = None)    # multiclass AUPRC \n",
    "    multilabel_auroc_mi = MultilabelAUROC(num_labels = 4, average = \"micro\", thresholds = None)    # multiclass AUROC\n",
    "    multilabel_auprc_mi = MultilabelAveragePrecision(num_labels = 4, average = \"micro\", thresholds = None)    # multiclass AUPRC \n",
    "\n",
    "    print(f\"Macro Acc: {macro_acc(preds, targets):.4f}\")\n",
    "    print(f\"Per Label Acc: {per_label_acc(preds, targets).detach().cpu().numpy()}\")\n",
    "    print(f\"Subset Acc: {subset_acc(preds, targets):.4f} | Marco-Ham: {ham_macro(preds, targets):.4f}\\n\")\n",
    "    \n",
    "    print(f\"Macro AUROC:  {multilabel_auroc_ma(preds, targets):.4f}         Macro AUPRC:  {multilabel_auprc_ma(preds, targets):.4f}\")\n",
    "\n",
    "target_names = [\"Right Upper\", \"Left Upper\", \"Left Lower\", \"Right Lower\"]\n",
    "compute_metrics(preds, targets, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae253180-7612-44c0-a8cf-81db00b1ce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-fold metrics:\n",
      "        n  subset_acc  macro_acc  macro_auroc  macro_auprc\n",
      "fold                                                      \n",
      "0     550      0.9255     0.9786       0.9934       0.9852\n",
      "1     551      0.9274     0.9778       0.9944       0.9915\n",
      "2     552      0.9167     0.9733       0.9910       0.9875\n",
      "3     551      0.9256     0.9787       0.9918       0.9905\n",
      "4     551      0.9310     0.9791       0.9883       0.9850\n",
      "5     548      0.9215     0.9767       0.9905       0.9903\n",
      "6     551      0.9328     0.9773       0.9939       0.9930\n",
      "7     551      0.9383     0.9819       0.9929       0.9922\n",
      "8     549      0.9199     0.9763       0.9858       0.9842\n",
      "9     551      0.9365     0.9814       0.9939       0.9895\n",
      "\n",
      "Per-label accuracy per fold:\n",
      "      acc_Right Upper  acc_Left Upper  acc_Left Lower  acc_Right Lower\n",
      "fold                                                                  \n",
      "0              0.9836          0.9818          0.9836           0.9655\n",
      "1              0.9855          0.9855          0.9728           0.9673\n",
      "2              0.9746          0.9656          0.9728           0.9801\n",
      "3              0.9855          0.9746          0.9782           0.9764\n",
      "4              0.9710          0.9800          0.9800           0.9855\n",
      "5              0.9745          0.9781          0.9763           0.9781\n",
      "6              0.9782          0.9855          0.9673           0.9782\n",
      "7              0.9800          0.9819          0.9855           0.9800\n",
      "8              0.9763          0.9690          0.9872           0.9727\n",
      "9              0.9855          0.9800          0.9782           0.9819\n",
      "mean           0.9795          0.9782          0.9782           0.9766\n",
      "\n",
      "Total samples (sum over folds): 5505\n",
      "\n",
      "Unweighted mean over folds:\n",
      "subset_acc: 0.9275\n",
      "macro_acc: 0.9781\n",
      "macro_auroc: 0.9916\n",
      "macro_auprc: 0.9889\n",
      "\n",
      "Std over folds:\n",
      "subset_acc: 0.0071\n",
      "macro_acc: 0.0025\n",
      "macro_auroc: 0.0028\n",
      "macro_auprc: 0.0032\n",
      "\n",
      "Pooled over all folds:\n",
      "n: 5505\n",
      "subset_acc: 0.9275\n",
      "macro_acc: 0.9781\n",
      "macro_auroc: 0.9908\n",
      "macro_auprc: 0.9873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchmetrics.classification import (\n",
    "    MultilabelAccuracy,\n",
    "    MultilabelHammingDistance,\n",
    "    MultilabelAUROC,\n",
    "    MultilabelAveragePrecision,\n",
    "    MultilabelExactMatch,\n",
    ")\n",
    "\n",
    "CSV_PATH = \"Saved/preds_targets_probs_40e_10f.csv\"  # change if needed\n",
    "FOLD_COL = \"Fold\"\n",
    "PRED_COL = \"Predictions\"\n",
    "TARG_COL = \"Targets\"\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# If you have explicit names, set them here. Otherwise they will be auto-generated.\n",
    "TARGET_NAMES = [\"Right Upper\", \"Left Upper\", \"Left Lower\", \"Right Lower\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Utils\n",
    "# ----------------------------\n",
    "def parse_array(s: str) -> np.ndarray:\n",
    "    return np.fromstring(str(s).strip(\"[]\"), sep=\" \")\n",
    "\n",
    "def _compute_fold_metrics(preds_np: np.ndarray,\n",
    "                          targets_np: np.ndarray,\n",
    "                          threshold: float = 0.5) -> dict:\n",
    "\n",
    "    preds_t   = torch.tensor(preds_np, dtype=torch.float32)\n",
    "    targets_t = torch.tensor(targets_np, dtype=torch.long)\n",
    "    num_labels = preds_t.size(1)\n",
    "\n",
    "    subset_acc = MultilabelExactMatch(num_labels=num_labels)\n",
    "    macro_acc  = MultilabelAccuracy(num_labels=num_labels, average=\"macro\",    threshold=threshold)\n",
    "    per_label  = MultilabelAccuracy(num_labels=num_labels, average=None,       threshold=threshold)\n",
    "\n",
    "    auroc_ma   = MultilabelAUROC(num_labels=num_labels, average=\"macro\")\n",
    "    auprc_ma   = MultilabelAveragePrecision(num_labels=num_labels, average=\"macro\")\n",
    "\n",
    "    out = {\n",
    "        \"n\":             int(preds_t.size(0)),\n",
    "        \"subset_acc\":    float(subset_acc(preds_t, targets_t)),\n",
    "        \"macro_acc\":     float(macro_acc(preds_t, targets_t)),\n",
    "        \"macro_auroc\":   float(auroc_ma(preds_t, targets_t)),\n",
    "        \"macro_auprc\":   float(auprc_ma(preds_t, targets_t)),\n",
    "        \"per_label_acc\": per_label(preds_t, targets_t).detach().cpu().numpy(),  # shape (C,)\n",
    "    }\n",
    "    return out\n",
    "\n",
    "def compute_metrics_by_fold(results_df: pd.DataFrame,\n",
    "                            target_names=None,\n",
    "                            fold_col: str = \"Fold\",\n",
    "                            pred_col: str = \"Predictions\",\n",
    "                            targ_col: str = \"Targets\",\n",
    "                            threshold: float = 0.5):\n",
    "\n",
    "    first_row = results_df[pred_col].iloc[0]\n",
    "    C = parse_array(first_row).shape[0]\n",
    "    if target_names is None:\n",
    "        target_names = [f\"Label_{i}\" for i in range(C)]\n",
    "    else:\n",
    "        assert len(target_names) == C, f\"len(target_names)={len(target_names)} but C={C}\"\n",
    "\n",
    "    folds = sorted(results_df[fold_col].unique())\n",
    "    per_fold_rows, per_label_rows = [], []\n",
    "\n",
    "    for f in folds:\n",
    "        df_f = results_df[results_df[fold_col] == f]\n",
    "\n",
    "        preds_np   = np.stack(df_f[pred_col].apply(parse_array).to_list()).astype(np.float32)  # (N_f, C)\n",
    "        targets_np = np.stack(df_f[targ_col].apply(parse_array).to_list()).astype(np.int64)    # (N_f, C)\n",
    "\n",
    "        fm = _compute_fold_metrics(preds_np, targets_np, threshold=threshold)\n",
    "\n",
    "        row = {\"fold\": f, \"n\": fm[\"n\"]}\n",
    "        for k in [\"subset_acc\",\"macro_acc\",\n",
    "                 \"macro_auroc\",\"macro_auprc\"]:\n",
    "            row[k] = fm[k]\n",
    "        per_fold_rows.append(row)\n",
    "\n",
    "        # per-label accuracy for this fold\n",
    "        pla = fm[\"per_label_acc\"]\n",
    "        pla_row = {\"fold\": f, **{f\"acc_{name}\": float(pla[i]) for i, name in enumerate(target_names)}}\n",
    "        per_label_rows.append(pla_row)\n",
    "\n",
    "    per_fold_df = pd.DataFrame(per_fold_rows).set_index(\"fold\").sort_index()\n",
    "    per_label_acc_df = pd.DataFrame(per_label_rows).set_index(\"fold\").sort_index()\n",
    "    per_label_acc_df.loc[\"mean\"] = per_label_acc_df.mean(axis=0)\n",
    "\n",
    "    return per_fold_df, per_label_acc_df, target_names\n",
    "\n",
    "def summarize_across_folds(per_fold_df: pd.DataFrame):\n",
    "\n",
    "    if \"n\" not in per_fold_df.columns:\n",
    "        raise ValueError(\"per_fold_df must contain 'n'\")\n",
    "\n",
    "    totals = {\"n\": int(per_fold_df[\"n\"].sum())}\n",
    "    metric_cols = [c for c in per_fold_df.columns if c != \"n\"]\n",
    "\n",
    "    unweighted_mean = per_fold_df[metric_cols].mean().to_dict()\n",
    "    std_over_folds = per_fold_df[metric_cols].std(ddof=1).to_dict()\n",
    "\n",
    "    return unweighted_mean, totals, std_over_folds\n",
    "\n",
    "def pooled_metrics(results_df: pd.DataFrame,\n",
    "                   pred_col=\"Predictions\",\n",
    "                   targ_col=\"Targets\",\n",
    "                   threshold=0.5) -> dict:\n",
    "\n",
    "    preds_np = np.stack(results_df[pred_col].apply(parse_array).to_list()).astype(np.float32)\n",
    "    targs_np = np.stack(results_df[targ_col].apply(parse_array).to_list()).astype(np.int64)\n",
    "    return _compute_fold_metrics(preds_np, targs_np, threshold=threshold)\n",
    "\n",
    "# ----------------------------\n",
    "# Run\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV\n",
    "    results_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "    # Compute per-fold metrics\n",
    "    per_fold_df, per_label_acc_df, target_names = compute_metrics_by_fold(\n",
    "        results_df,\n",
    "        target_names=TARGET_NAMES,\n",
    "        fold_col=FOLD_COL,\n",
    "        pred_col=PREDCOL if (PREDCOL := PRED_COL) else \"Predictions\",  # defensive alias\n",
    "        targ_col=TARGCOL if (TARGCOL := TARG_COL) else \"Targets\",\n",
    "        threshold=THRESHOLD\n",
    "    )\n",
    "\n",
    "    # Summaries across folds\n",
    "    unweighted_mean, totals, std_over_folds = summarize_across_folds(per_fold_df)\n",
    "\n",
    "    # Pooled metrics\n",
    "    pooled = pooled_metrics(results_df, pred_col=PRED_COL, targ_col=TARG_COL, threshold=THRESHOLD)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Print results\n",
    "    # ----------------------------\n",
    "    pd.set_option(\"display.width\", 180)\n",
    "    pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "    print(\"\\nPer-fold metrics:\")\n",
    "    print(per_fold_df.round(4))\n",
    "\n",
    "    print(\"\\nPer-label accuracy per fold:\")\n",
    "    print(per_label_acc_df.round(4))\n",
    "\n",
    "    print(f\"\\nTotal samples (sum over folds): {totals['n']}\")\n",
    "\n",
    "    print(\"\\nAverage over folds:\")\n",
    "    for k, v in unweighted_mean.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\nStd over folds:\")\n",
    "    for k, v in std_over_folds.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\nPooled over all folds:\")\n",
    "    for k, v in pooled.items():\n",
    "        if k == \"per_label_acc\":\n",
    "            continue\n",
    "        if k == \"n\":\n",
    "            print(f\"{k}: {int(v)}\")\n",
    "        else:\n",
    "            print(f\"{k}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-pytorch",
   "language": "python",
   "name": "env-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
